{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, re\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy import sparse\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print 'Data Loaded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32       \"\\nBan one side of an argument by a bullshit n...\n",
       "81       \"\\n\\nIt was very constructive you are just ver...\n",
       "86       \"\\n\\n You know what? Fuck you! I tried to be c...\n",
       "104      \"\\n\\n Corrected spelling of \"\"recognised\"\" to ...\n",
       "122      your time....\\n\\nYou suck because you are RIGH...\n",
       "124                           YOU NEED A PUSSY, YOUR GEEK!\n",
       "160      loser, get a life\\n\\nyou must be fat, ugly and...\n",
       "213      F'UCK YOU ADMINISTRATORS (I WILL BE BACK TO TR...\n",
       "292      Jimbo is bending over backwards so hard to do ...\n",
       "307      Another stupid person who considers leaving a ...\n",
       "308      These Iranian bastards are at it again. Not on...\n",
       "330                        is the sock puppet of ,fuck off\n",
       "352      Idiots\\n\\nThe Barris batmobile did not have a ...\n",
       "436            you are a stupid ass hole thats my  message\n",
       "459                                  alex fuck you \\n\\n...\n",
       "480      AH HAAHHAHAHAH YAAA BITCH YAAAA!@!!!!!!AH HAAH...\n",
       "490                              fucking loser suck a dick\n",
       "511      WikiTheClown\\nWelcome to Wikipedia. Although e...\n",
       "571      \"\\n\\n The Great One! \\nI dont really have a pr...\n",
       "577      STOP YOUR DAMN NONSENSE LUMINIFER!!!!!  YOU HA...\n",
       "587                          fuck you i will edit anything\n",
       "595      probably that you are a german... fucking germ...\n",
       "616      Show up again when you figure out how to rub t...\n",
       "626      and your a fucking fat wanker with no life. si...\n",
       "633      hey you dumb bitch if i cant spell saturn girl...\n",
       "665      Eat a Dick, Lucasbfr \\n\\nYo . i'm [[User:Cool ...\n",
       "674      who are you? \\n\\nwho the hell are you and why ...\n",
       "708                        Screw my Butt \\n\\nScrew my Butt\n",
       "714                     blow \\n\\nit out of your ass, spic.\n",
       "730      <- Someone doesn't listen to Propagandhi. I pi...\n",
       "                               ...                        \n",
       "95108    \"\\n\\nFuck off you stupid fucking retard cunt.\\...\n",
       "95157                            SO YOU ADMIT YOURE A FAG?\n",
       "95165    Congrats  \\n\\nCongrats that the wikidouchebags...\n",
       "95189    You, too can join the ranks of looking-to-be-o...\n",
       "95203    wikipedia search warrior4321 \\n\\nyour a dickhe...\n",
       "95220    FUCK U DENNIS BURN IN HELL YOU SON OF A BITCH ...\n",
       "95269    Fuck you 2.0 \\n\\nYou are an idiot and an admin...\n",
       "95282    What a retard, that . Shut your FUD up, you ar...\n",
       "95287    hey faggot. \\n\\nInsert non-formatted text here...\n",
       "95301    THESE WIKIPEDIA PEOPLE ARE LIARS AND FASCISTS ...\n",
       "95337    fuck wikipidia \\n\\nand fuck you.\\n\\nFuck this ...\n",
       "95357    Kind Sir, why dont you try to lick my butthole...\n",
       "95362    metalcore is NOT a punk genre you fucking idio...\n",
       "95370    Why are you harassing me, when you have never ...\n",
       "95398    Diem was a gay homosexual dictator \\nThis fact...\n",
       "95399    The above user, who has failed to sign, is ign...\n",
       "95411                              your a peace of ass!!!!\n",
       "95412              Go fuck yourself and block me you cunt.\n",
       "95423    Yall are vandals\\n\\nI like Tyar and Stopdropro...\n",
       "95426    Wrestling with a pig \\n\\nWell, you know what t...\n",
       "95430    You are the biggest and dumbest idiot I have e...\n",
       "95498    There are some pathetic people on Wikipedia to...\n",
       "95517    Layne Staley\\nwho told you that you crackhead,...\n",
       "95542    IN THE anus with a nigger dick in it.68.33.41.181\n",
       "95576           Try the official website then - shit head!\n",
       "95702    Licking my ass \\nHahaha quit banning me you fa...\n",
       "95718    Suitcivil133 is a little bitch. he is a bandwa...\n",
       "95731                           get a proper job daft cunt\n",
       "95741    so, who the fuck gives a damn, you dipshitted ...\n",
       "95751    asshole and Richard Simmons's asshole, and ass...\n",
       "Name: comment_text, Length: 4765, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5109\n",
    "train_df['comment_text'][(train_df.insult == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "toRemove = ['\\n', '\\t', '\\r']\n",
    "printable = set(string.printable)\n",
    "def preprocess(row):    \n",
    "    try:\n",
    "        comment = row['comment_text']\n",
    "        comment = filter(lambda x: x in printable, comment)\n",
    "        for ele in toRemove:\n",
    "            comment = comment.replace(ele, '')\n",
    "        comment = comment.translate(None, string.punctuation)\n",
    "        #Remove user mention\n",
    "        comment = re.sub('@[^\\s]+','',comment)\n",
    "        comment = \" \".join([lemmatizer.lemmatize(word) for word in comment.split(\" \")])\n",
    "        \n",
    "        words = comment.split(' ')\n",
    "        upperCaseWords = filter(lambda x: x.isupper(), words)\n",
    "        row['ProcessedText'] = comment\n",
    "        row['wordCount'] = len(words)\n",
    "        row['shouting words'] = len(upperCaseWords)\n",
    "    except Exception as e:\n",
    "        print '\\n\\n The comment could not be processed \\n\\n', row, e.message\n",
    "        row[\"ProcessedText\"] = \"unknown\"\n",
    "        row[\"wordCount\"] = 1\n",
    "        row[\"shouting words\"] = 0\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that could probably help after the initial model is built\n",
    "1. Check for words with all caps letter, and note the count of it and if the whole comments is in all caps\n",
    "2. Make/Get a list of expletives used\n",
    "3. Make features specific to each of the different attack types\n",
    "    a. toxic/server_toxic - list of expletives and deragotary terms\n",
    "    b. identity_hate - country / religion name or other identities like - liberal, Conservative or Gender\n",
    "    c. Threat - Action by the speaker\n",
    "    d. insult ?? if toxic and directed towards someone\n",
    "4. use word2vec and create a KNN sort of model for prediction\n",
    "\n",
    "\n",
    "The first set of models that we will try are Naive Bayes, SVM and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>id</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "      <th>ProcessedText</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>shouting words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ExplanationWhy the edits made under my usernam...</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Daww He match this background colour Im seemin...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hey man Im really not trying to edit war Its j...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MoreI cant make any real suggestion on improve...</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text                id  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...  0000997932d777bf   \n",
       "1  D'aww! He matches this background colour I'm s...  000103f0d9cfb60f   \n",
       "2  Hey man, I'm really not trying to edit war. It...  000113f07ec002fd   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...  0001b41b1c6bb37e   \n",
       "4  You, sir, are my hero. Any chance you remember...  0001d958c54c6e35   \n",
       "\n",
       "   identity_hate  insult  obscene  severe_toxic  threat  toxic  \\\n",
       "0            0.0     0.0      0.0           0.0     0.0    0.0   \n",
       "1            0.0     0.0      0.0           0.0     0.0    0.0   \n",
       "2            0.0     0.0      0.0           0.0     0.0    0.0   \n",
       "3            0.0     0.0      0.0           0.0     0.0    0.0   \n",
       "4            0.0     0.0      0.0           0.0     0.0    0.0   \n",
       "\n",
       "                                       ProcessedText  wordCount  \\\n",
       "0  ExplanationWhy the edits made under my usernam...         42   \n",
       "1  Daww He match this background colour Im seemin...         18   \n",
       "2  Hey man Im really not trying to edit war Its j...         42   \n",
       "3  MoreI cant make any real suggestion on improve...        112   \n",
       "4  You sir are my hero Any chance you remember wh...         13   \n",
       "\n",
       "   shouting words  \n",
       "0               2  \n",
       "1               1  \n",
       "2               0  \n",
       "3               4  \n",
       "4               0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedDf = train_df.append(test_df)\n",
    "combinedDf = combinedDf.apply(preprocess, axis=1)\n",
    "combinedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>id</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "      <th>ProcessedText</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>shouting words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ExplanationWhy the edits made under my usernam...</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Daww He match this background colour Im seemin...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hey man Im really not trying to edit war Its j...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MoreI cant make any real suggestion on improve...</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text                id  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...  0000997932d777bf   \n",
       "1  D'aww! He matches this background colour I'm s...  000103f0d9cfb60f   \n",
       "2  Hey man, I'm really not trying to edit war. It...  000113f07ec002fd   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...  0001b41b1c6bb37e   \n",
       "4  You, sir, are my hero. Any chance you remember...  0001d958c54c6e35   \n",
       "\n",
       "   identity_hate  insult  obscene  severe_toxic  threat  toxic  \\\n",
       "0            0.0     0.0      0.0           0.0     0.0    0.0   \n",
       "1            0.0     0.0      0.0           0.0     0.0    0.0   \n",
       "2            0.0     0.0      0.0           0.0     0.0    0.0   \n",
       "3            0.0     0.0      0.0           0.0     0.0    0.0   \n",
       "4            0.0     0.0      0.0           0.0     0.0    0.0   \n",
       "\n",
       "                                       ProcessedText  wordCount  \\\n",
       "0  ExplanationWhy the edits made under my usernam...         42   \n",
       "1  Daww He match this background colour Im seemin...         18   \n",
       "2  Hey man Im really not trying to edit war Its j...         42   \n",
       "3  MoreI cant make any real suggestion on improve...        112   \n",
       "4  You sir are my hero Any chance you remember wh...         13   \n",
       "\n",
       "   shouting words  \n",
       "0               2  \n",
       "1               1  \n",
       "2               0  \n",
       "3               4  \n",
       "4               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def wordProcessing(row):\n",
    "    words = row['ProcessedText'].split(' ')\n",
    "    upperCaseWords = filter(lambda x: x.isupper(), words)\n",
    "    row['wordCount'] = len(words)\n",
    "    row['shouting words'] = len(upperCaseWords)\n",
    "    return row\n",
    "combinedDf = combinedDf.apply(wordProcessing, axis=1)\n",
    "'''\n",
    "combinedDf = pd.read_csv('combinedProcessedDataSet.csv')\n",
    "combinedDf.head()\n",
    "#combinedDf.to_csv('combinedProcessedDataSet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_cols = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "combinedDf['none'] = 1-combinedDf[label_cols].max(axis=1)\n",
    "combinedDf = combinedDf.reset_index(drop=True)\n",
    "combinedDf['percentShout'] = combinedDf['shouting words'] / (combinedDf['wordCount'] + 1)\n",
    "testData = combinedDf.loc[train_df.shape[0]:].copy()\n",
    "trainData, valData = train_test_split(combinedDf.loc[: train_df.shape[0] - 1].copy(), test_size = 0.1)\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.9, stop_words='english',\n",
    "                      strip_accents='unicode', use_idf=1,\n",
    "                      smooth_idf=1, sublinear_tf=1, max_features = 800000)\n",
    "trn_term_doc = pd.DataFrame(vec.fit_transform(trainData['ProcessedText']).todense())\n",
    "test_term_doc = pd.DataFrame(vec.transform(testData['ProcessedText'].fillna(\"unknown\")).todense())\n",
    "val_term_doc = pd.DataFrame(vec.transform(valData['ProcessedText'].fillna(\"unknown\")).todense())\n",
    "\n",
    "colsCopy = ['wordCount', 'shouting words', 'percentShout']\n",
    "for col in colsCopy:\n",
    "    trn_term_doc[col] = trainData[col].values\n",
    "    test_term_doc[col] = testData[col].values\n",
    "    val_term_doc[col] = valData[col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defines NB SVM model\n",
    "class nbsvm():\n",
    "    def pr(self, y_i, y, data):\n",
    "        p = data[y==y_i].sum(0)\n",
    "        return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "    def fit(self, data, y):\n",
    "        y = y.values\n",
    "        #print 'y shape', y.shape\n",
    "        r = np.log(self.pr(1,y, data) / self.pr(0,y, data))\n",
    "        m = LogisticRegression(C=4, dual=True)\n",
    "        x_nb = np.multiply(r.reshape(1, len(r)), data.values)\n",
    "        #print np.isnan(x_nb).any(), np.isnan(y).any(), np.isinf(x_nb).any(), np.isinf(y).any()\n",
    "        self.model = (m.fit(x_nb, y), r)\n",
    "        return self.model\n",
    "    \n",
    "    def predict_proba(self, data):\n",
    "        m, r = self.model\n",
    "        return m.predict_proba(np.multiply(r.reshape(1, len(r)), data.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: nbsvm\n",
      "fit: toxic\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "models = [('nbsvm', nbsvm()), ('extraTreeClassifier', ExtraTreesClassifier(n_jobs=-1, random_state=3))]\n",
    "for mdlName, mdl in models:\n",
    "    preds = np.zeros((val_term_doc.shape[0], len(label_cols)))\n",
    "    print'Model Name:', mdlName\n",
    "    for i, j in enumerate(label_cols):\n",
    "        print 'fit:', j\n",
    "        mdl.fit(trn_term_doc, trainData[j].reset_index(drop=True))\n",
    "        preds[:,i] = mdl.predict_proba(val_term_doc)[:, 1]\n",
    "    \n",
    "    lossValue = []\n",
    "    for i, col in enumerate(label_cols):\n",
    "        lossValue.append(roc_auc_score(valData[col], preds[:, i]))\n",
    "    print 'Loss Value', np.array(lossValue).mean()\n",
    "    print '*'* 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15958, 240422)\n",
      "(143613, 240422)\n",
      "(153164, 240422)\n"
     ]
    }
   ],
   "source": [
    "print val_term_doc.shape\n",
    "print trn_term_doc.shape\n",
    "print test_term_doc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = np.zeros((test_term_doc.shape[0], len(label_cols)))\n",
    "trn_term_doc = trn_term_doc.append(val_term_doc)\n",
    "trainData = trainData.append(valData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [('nbsvm', nbsvm()), ('extraTreeClassifier', ExtraTreesClassifier(n_jobs=-1, random_state=3))]\n",
    "for mdlName, mdl in models:\n",
    "    preds = np.zeros((val_term_doc.shape[0], len(label_cols)))\n",
    "    print('Model Name', mdlName)\n",
    "    for i, j in enumerate(label_cols):\n",
    "        print('fit', j)\n",
    "        mdl.fit(trn_term_doc, trainData[j].reset_index(drop=True))\n",
    "        preds[:,i] = mdl.predict_proba(test_term_doc)[:,1]\n",
    "    submid = pd.DataFrame({'id': map(lambda x: str(x), testData[\"id\"].values)})\n",
    "    submission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n",
    "    #print submission.shape, submission.dtypes\n",
    "    submission.to_csv(mdlName + '_shoutingwords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226998, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [('nbsvm', nbsvm()), ('extraTreeClassifier', ExtraTreesClassifier(n_jobs=-1, random_state=3))]\n",
    "for mdlName, mdl in models:\n",
    "    preds = np.zeros((val_term_doc.shape[0], len(label_cols)))\n",
    "    print'Model Name:', mdlName\n",
    "    for i, j in enumerate(label_cols):\n",
    "        print 'fit:', j\n",
    "        mdl.fit(trn_term_doc, trainData[j].reset_index(drop=True))\n",
    "        preds[:,i] = mdl.predict_proba(val_term_doc)[:, 1]\n",
    "    \n",
    "    lossValue = []\n",
    "    for i, col in enumerate(label_cols):\n",
    "        lossValue.append(roc_auc_score(valData[col], preds[:, i]))\n",
    "    print 'Loss Value', np.array(lossValue).mean()\n",
    "    print '*'* 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submid = pd.DataFrame({'id': map(lambda x: str(x), testData[\"id\"].values)})\n",
    "submission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n",
    "#print submission.shape, submission.dtypes\n",
    "submission.to_csv('NBSVM_shoutingwords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 7)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'toxic', u'severe_toxic', u'obscene', u'threat', u'insult',\n",
       "       u'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322849, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the NBSVM model\n",
    "2. Create Bidirectional LSTM model\n",
    "3. Create LSTM-NBSVM model\n",
    "4. Use word to vector for data representation, things are from wikipedia so there should be doc2vec rep for them\n",
    "5. Create a list of communities/nationality/gender etc and using entity extraction check for existence of such communities or just via text match\n",
    "6. Follow the steps given here to build a better model. https://cyberbullying.org/machine-learning-can-help-us-combat-online-abuse-primer\n",
    "7. Papers to read for feature engineering - https://arxiv.org/pdf/1702.06877.pdf, https://faculty.ist.psu.edu/xu/papers/Chen_etal_SocialCom_2012.pdf\n",
    "8. Check for existence of third second person pronouns and close meaning such as “ur”\n",
    "9. https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/blob/master/en\n",
    "\n",
    "The list of bad words needs to be broken down into multiple lists as they are very much different\n",
    "1. Profane words\n",
    "2. Sexual words\n",
    "3. community words - words used to define a community\n",
    "4. Racial slurs\n",
    "\n",
    "In each of the list group the words into 3 categories [low, medium, high] which define the chance that the word can be used in a negative way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "secondPersonPronoun = ['you', 'ur', 'your', 'yours']\n",
    "thirdPersonPronoun = ['they', 'those', 'them', 'their', 'theirs', 'these']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
